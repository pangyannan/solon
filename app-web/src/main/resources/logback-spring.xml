<?xml version="1.0" encoding="UTF-8"?>
<!--如若配置方式无法兼容应用方式，可以自定义xml的方式-->
<!-- 从高到地低 OFF 、 FATAL 、 ERROR 、 WARN 、 INFO 、 DEBUG 、 TRACE 、 ALL -->
<!-- 日志输出规则 根据当前ROOT 级别，日志输出时，级别高于root默认的级别时 会输出 -->
<!-- 以下 每个配置的 filter 是过滤掉输出文件里面，会出现高级别文件，依然出现低级别的日志信息，通过filter 过滤只记录本级别的日志 -->
<!-- 属性描述 scan：性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true scanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。 
	debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 -->
<configuration scan="true" scanPeriod="60 seconds" debug="false">
	<!--读取spring环境变量-->
	<springProperty scope="context" name="APP_NAME" source="spring.application.name" defaultValue="solon" />
	<!--读取spring环境变量，定义日志的跟路径-->
	<springProperty scope="context" name="LOG_PATH" source="logging.logback.path" defaultValue="logs" />
	<!--读取spring环境变量，定义日志的保存天数-->
	<springProperty scope="context" name="MAX_HISTORY" source="logging.logback.rollingpolicy.maxHistory" defaultValue="90" />
	<!--读取spring环境变量，定义单个日志的大小，超过整个大小会自动归档-->
	<springProperty scope="context" name="MAX_FILE_SIZE" source="logging.logback.rollingpolicy.maxFileSize" defaultValue="256MB" />


	<!-- ConsoleAppender 控制台输出日志 -->
	<appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
		<!-- 对日志进行格式化 控制台使用彩色输出-->
		<encoder>
			<pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] [%X{traceId}] %highlight(%-5level) %cyan(%logger{20}) - %msg %n</pattern>
			<charset>UTF-8</charset>
		</encoder>
	</appender>


	<!-- INFO级别日志 appender -->
	<appender name="INFO_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
		<!-- 过滤器，只记录INFO级别的日志 -->
		<filter class="ch.qos.logback.classic.filter.LevelFilter">
			<level>INFO</level>
			<onMatch>ACCEPT</onMatch>
			<onMismatch>DENY</onMismatch>
		</filter>
		<!--当前日志存放路径-->
		<file>${LOG_PATH}/${APP_NAME}/info.log</file>
		<!--按照日期大大小归档日志-->
		<rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
			<!-- 历史日志文件的存放路径和名称 gz表示自动压缩-->
			<fileNamePattern>${LOG_PATH}/${APP_NAME}/info.%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
			<!-- 日志最大保存天数 -->
			<maxHistory>${MAX_HISTORY}</maxHistory>
			<!--日志大小-->
			<maxFileSize>${MAX_FILE_SIZE}</maxFileSize>
		</rollingPolicy>
		<encoder>
			<pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] [%X{traceId}] %-5level %logger - %msg%n</pattern>
		</encoder>
	</appender>
	<!-- 异步输出,在高并发下性能明显提升 -->
	<appender name="ASYNC_INFO_FILE" class="ch.qos.logback.classic.AsyncAppender">
		<!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
		<discardingThreshold>0</discardingThreshold>
		<!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
		<queueSize>1024</queueSize>
		<!-- 添加附加的appender,最多只能添加一个 -->
		<appender-ref ref="INFO_FILE"/>
	</appender>



	<!-- WARN及以上级别日志 appender -->
	<appender name="WARN_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
		<!-- 过滤器，只记录INFO级别的日志 -->
		<filter class="ch.qos.logback.classic.filter.ThresholdFilter">
			<level>WARN</level>
		</filter>
		<!--当前日志存放路径-->
		<file>${LOG_PATH}/${APP_NAME}/warn.log</file>
		<!--按照日期大大小归档日志-->
		<rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
			<!-- 历史日志文件的存放路径和名称 gz表示自动压缩-->
			<fileNamePattern>${LOG_PATH}/${APP_NAME}/warn.%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
			<!-- 日志最大保存天数 -->
			<maxHistory>${MAX_HISTORY}</maxHistory>
			<!--日志大小-->
			<maxFileSize>${MAX_FILE_SIZE}</maxFileSize>
		</rollingPolicy>
		<encoder>
			<pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] [%X{traceId}] %-5level %logger - %msg%n</pattern>
		</encoder>
	</appender>
	<!-- 异步输出,在高并发下性能明显提升 -->
	<appender name="ASYNC_WARN_FILE" class="ch.qos.logback.classic.AsyncAppender">
		<!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
		<discardingThreshold>0</discardingThreshold>
		<!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
		<queueSize>1024</queueSize>
		<!-- 添加附加的appender,最多只能添加一个 -->
		<appender-ref ref="WARN_FILE"/>
	</appender>



	<!-- 一个日志文件记录 appender -->
	<appender name="ALL_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
		<!-- 过滤器，只记录INFO级别的日志 -->
		<filter class="ch.qos.logback.classic.filter.ThresholdFilter">
			<level>ALL</level>
		</filter>
		<!--当前日志存放路径-->
		<file>${LOG_PATH}/${APP_NAME}/all.log</file>
		<!--按照日期大大小归档日志-->
		<rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
			<!-- 历史日志文件的存放路径和名称 gz表示自动压缩-->
			<fileNamePattern>${LOG_PATH}/${APP_NAME}/all.%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
			<!-- 日志最大保存天数 -->
			<maxHistory>${MAX_HISTORY}</maxHistory>
			<!--日志大小-->
			<maxFileSize>${MAX_FILE_SIZE}</maxFileSize>
		</rollingPolicy>
		<encoder>
			<pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] [%X{traceId}] %-5level %logger - %msg%n</pattern>
		</encoder>
	</appender>
	<!-- 异步输出,在高并发下性能明显提升 -->
	<appender name="ASYNC_ALL_FILE" class="ch.qos.logback.classic.AsyncAppender">
		<!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
		<discardingThreshold>0</discardingThreshold>
		<!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
		<queueSize>1024</queueSize>
		<!-- 添加附加的appender,最多只能添加一个 -->
		<appender-ref ref="ALL_FILE"/>
	</appender>


	<!-- 一个日志文件记录 appender -->
	<appender name="AUDIT_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
		<!-- 过滤器，只记录INFO级别的日志 -->
		<filter class="ch.qos.logback.classic.filter.ThresholdFilter">
			<level>INFO</level>
		</filter>
		<!--当前日志存放路径-->
		<file>${LOG_PATH}/${APP_NAME}/audit.log</file>
		<!--按照日期大大小归档日志-->
		<rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
			<!-- 历史日志文件的存放路径和名称 gz表示自动压缩-->
			<fileNamePattern>${LOG_PATH}/${APP_NAME}/audit.%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
			<!-- 日志最大保存天数 -->
			<maxHistory>${MAX_HISTORY}</maxHistory>
			<!--日志大小-->
			<maxFileSize>${MAX_FILE_SIZE}</maxFileSize>
		</rollingPolicy>
		<encoder>
			<pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] [%X{traceId}] %-5level %logger - %msg%n</pattern>
		</encoder>
	</appender>


	<logger name="org.springframework" level="INFO" />
	<logger name="_org.springframework.web.servlet.HandlerMapping.Mappings" level="INFO" /> <!--主要是打印了路径映射关系,不需要-->
	<logger name="io.lettuce.core.protocol" level="INFO" />
	<logger name="io.lettuce.core.RedisChannelHandler" level="INFO" />
	<logger name="com.zaxxer.hikari" level="INFO" />

	<logger name="org.apache" level="INFO" />
	<logger name="org.apache.http.wire" level="INFO" />
	<logger name="org.apache.http.headers" level="INFO" />


	<!--开发环境配置-->
	<springProfile name="dev">
		<!-- root节点：启动配置以及定义日志的输出级别
     root节点实际上是配置启用哪种appender，可以添加多个appender。-->
		<root level="DEBUG">
			<appender-ref ref="STDOUT" />
		</root>
	</springProfile>


	<!--测试环境配置-->
	<springProfile name="test">
		<root level="DEBUG">
			<appender-ref ref="STDOUT" />
			<!-- 文件输出 -->
			<appender-ref ref="ALL_FILE" />
		</root>
		<!--将审计日志单独打印到审计日志中 additivity="true"表示继续传递到父日志中-->
		<logger name="AuditLogStore" additivity="ture" level="INFO">
			<appender-ref ref="AUDIT_FILE"/>
		</logger>
	</springProfile>

	<!--生产环境配置-->
	<springProfile name="prod">
		<root level="INFO">
			<!-- 文件输出,默认采用同步模式打印日志
				如果高性能模式，可以配置 ASYNC_INFO_FILE + ASYNC_WARN_FILE
				如果是要记录在一个文件中，不区分文件，则可以使用 ALL_FILE 或 ASYNC_ALL_FILE
			-->
			<!-- 文件输出 -->
<!--			<appender-ref ref="ASYNC_INFO_FILE" />-->
<!--			<appender-ref ref="ASYNC_WARN_FILE" />-->
			<appender-ref ref="ASYNC_ALL_FILE" />
		</root>
		<!--将审计日志单独打印到审计日志中 additivity="true"表示继续传递到父日志中-->
		<logger name="AuditLogStore" additivity="ture" level="INFO">
			<appender-ref ref="AUDIT_FILE"/>
		</logger>
	</springProfile>

</configuration>